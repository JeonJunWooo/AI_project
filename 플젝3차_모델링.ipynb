{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMIz+S5z1vZ6WvsHDA/uB+/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeonJunWooo/mini_project/blob/main/%ED%94%8C%EC%A0%9D3%EC%B0%A8_%EB%AA%A8%EB%8D%B8%EB%A7%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z9eV3AT8WrY_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩 사용 시 구글 드라이브 연결\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-IXUPoeWyFj",
        "outputId": "b7e3de9c-3bee-4da8-e83b-36368f7b7cac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ROOT_PATH 확인 \n",
        "import os\n",
        "\n",
        "if os.getcwd() == '/content' :\n",
        "  # 구글 드라이브 사용 시 \n",
        "  ROOT_PATH = \"/content/drive/MyDrive/AIVLE_3rd_Team\"\n",
        "else :\n",
        "  ROOT_PATH = os.path.abspath('..')\n",
        "\n",
        "# 비디오 파일이 저장되어 있는 폴더\n",
        "VIDEO_PATH = ROOT_PATH + \"/video/train/train_video\"\n",
        "\n",
        "# 모델 학습을 위한 데이터 \n",
        "TRAIN_PATH = ROOT_PATH + \"/train/image\"\n",
        "# 모델 예측을 위한 test 데이터\n",
        "TEST_PATH = ROOT_PATH + \"/test\"\n",
        "# MODEL 저장 경로\n",
        "MODEL_PATH = ROOT_PATH + \"/model\""
      ],
      "metadata": {
        "id": "T2jKGY4yWyrL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. ImageDataGenerator 생성하기"
      ],
      "metadata": {
        "id": "ufzuAlRMYLi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import shuffle\n",
        "# 실습해보세요.\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "img_height = 480\n",
        "img_width = 854\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,  # 이미지 데이터 정규화\n",
        "    validation_split=0.2, # train, validation 데이터 분할 (8:2)\n",
        "    fill_mode='nearest',\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "# train_genrator 생성\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_PATH,\n",
        "    batch_size = 16,\n",
        "    target_size=(480, 854),\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'training',\n",
        "    color_mode= 'grayscale'\n",
        ")\n",
        "\n",
        "# validation_generator 생성\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_PATH, \n",
        "    batch_size= 16,\n",
        "    target_size=(img_height, img_width),\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'validation',\n",
        "    color_mode= 'grayscale'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptp2SmUaYCQ0",
        "outputId": "9d75e2c9-5ffd-4fdd-ce75-b90b33533967"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 503 images belonging to 4 classes.\n",
            "Found 123 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 구성하기"
      ],
      "metadata": {
        "id": "l1Yj0R7oYVEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras.losses import categorical_crossentropy, sparse_categorical_crossentropy\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.layers import BatchNormalization, Dropout\n",
        "\n",
        "import random as rd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "y3vvkHp5YWbY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height, img_width"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzDHRJTYYYKv",
        "outputId": "df831b65-bf9e-4daf-ac85-fbcc5187380a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(480, 854)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 세션클리어\n",
        "clear_session()\n",
        "\n",
        "## 모델 선언\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "# 인풋레이어\n",
        "model.add(keras.layers.Input(shape=(img_height,img_width,1)))\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=32,\n",
        "                              kernel_size = (3,3),\n",
        "                              padding = 'same',\n",
        "                              activation = 'relu',\n",
        "                              ))\n",
        "BatchNormalization()\n",
        "model.add(keras.layers.MaxPool2D(pool_size=(2,2),\n",
        "                                 strides = (3,3)))\n",
        "Dropout(0.25)\n",
        "model.add(keras.layers.Conv2D(filters=32,\n",
        "                              kernel_size = (3,3),\n",
        "                              padding = 'same',\n",
        "                              activation = 'relu',\n",
        "                              ))\n",
        "model.add(keras.layers.MaxPool2D(pool_size=(2,2),\n",
        "                                 strides = (3,3)))\n",
        "Dropout(0.25)\n",
        "model.add( layers.Flatten() )\n",
        "model.add( layers.Dense(16, activation='relu') )\n",
        "BatchNormalization()\n",
        "Dropout(0.35)\n",
        "\n",
        "# 아웃풋레이어\n",
        "model.add( layers.Dense(4, activation='softmax') )\n",
        "\n",
        "\n",
        "\n",
        "##요약\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jO_hZlrYhMl",
        "outputId": "e18606df-d5a0-43c9-b9af-1ace4affd9db"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 480, 854, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 160, 285, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 160, 285, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 53, 95, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 161120)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                2577936   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,587,572\n",
            "Trainable params: 2,587,572\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 컴파일 \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "# early_stopping \n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=MODEL_PATH,\n",
        "    monitor='val_loss',   # val_loss 값이 개선되었을때 호출됩니다\n",
        "    verbose=1,            # 로그를 출력합니다\n",
        "    save_best_only=True,  # 가장 best 값만 저장합니다\n",
        "    mode='auto'           # auto는 알아서 best를 찾습니다. min/max\n",
        ")\n",
        "\n",
        "\n",
        "# early_stopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor= 'val_loss',\n",
        "    min_delta = 0,\n",
        "    patience = 5,\n",
        "    verbose = 1,\n",
        "    restore_best_weights = True\n",
        ")\n"
      ],
      "metadata": {
        "id": "URSnqJTkYkzq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "\ttrain_generator,\n",
        "    steps_per_epoch=15, #한 번의 epoch를 돌 때, 데이터를 몇 번 볼 것인가\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping,checkpoint],\n",
        "    validation_data = validation_generator,\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1J3v1wpYn-C",
        "outputId": "01fcf146-ec04-4712-804e-5a0e9b1f3363"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.0304 - accuracy: 0.6710\n",
            "Epoch 1: val_loss improved from inf to 0.47005, saving model to /content/drive/MyDrive/AIVLE_3rd_Team/model\n",
            "15/15 [==============================] - 84s 5s/step - loss: 1.0304 - accuracy: 0.6710 - val_loss: 0.4700 - val_accuracy: 0.7642\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2006 - accuracy: 0.9458\n",
            "Epoch 2: val_loss improved from 0.47005 to 0.06377, saving model to /content/drive/MyDrive/AIVLE_3rd_Team/model\n",
            "15/15 [==============================] - 25s 2s/step - loss: 0.2006 - accuracy: 0.9458 - val_loss: 0.0638 - val_accuracy: 0.9919\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 3: val_loss did not improve from 0.06377\n",
            "15/15 [==============================] - 12s 762ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9919\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.9940e-04 - accuracy: 1.0000\n",
            "Epoch 4: val_loss did not improve from 0.06377\n",
            "15/15 [==============================] - 7s 469ms/step - loss: 3.9940e-04 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9919\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.0336e-04 - accuracy: 1.0000\n",
            "Epoch 5: val_loss did not improve from 0.06377\n",
            "15/15 [==============================] - 4s 282ms/step - loss: 1.0336e-04 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9919\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - ETA: 0s - loss: 6.9404e-05 - accuracy: 1.0000\n",
            "Epoch 6: val_loss did not improve from 0.06377\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 6.9404e-05 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9919\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - ETA: 0s - loss: 5.4145e-05 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 2.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.06377\n",
            "15/15 [==============================] - 2s 146ms/step - loss: 5.4145e-05 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9919\n",
            "Epoch 7: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 저장\n",
        "model.save_weights(MODEL_PATH + '/my_weight.h5')\n",
        "\n",
        "#  weight만 불러오기\n",
        "model.load_weights(MODEL_PATH + '/my_weight.h5')\n",
        "\n",
        "\n",
        "#  모델 통째로 저장\n",
        "model.save(MODEL_PATH + '/팀_미니프로젝트3차_a206205_전준우.h5')\n",
        "\n"
      ],
      "metadata": {
        "id": "XlGEpacjYq9A"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}